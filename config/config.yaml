# Rock-Paper-Scissors CNN Project Configuration

# Data Configuration
data:
  raw_path: "data/raw"
  processed_path: "data/processed"
  image_size: [128, 128]  # [height, width] - reduced for faster training
  batch_size: 64  # increased batch size for faster training
  validation_split: 0.2
  test_split: 0.1
  random_seed: 42

# Data Augmentation
augmentation:
  rotation_range: 20
  width_shift_range: 0.1
  height_shift_range: 0.1
  horizontal_flip: true
  zoom_range: 0.1
  fill_mode: "nearest"

# Model Configuration
models:
  # Simple CNN
  simple_cnn:
    conv_layers: 2
    filters: [16, 32]
    kernel_size: 3
    activation: "relu"
    dropout: 0.25
    dense_units: 64
    
  # Medium CNN - Fixed overfitting with proper regularization
  medium_cnn:
    conv_layers: 3
    filters: [32, 64, 128]
    kernel_size: 3
    activation: "relu"
    dropout: 0.3
    dense_units: 128
    use_batch_norm: true
    use_global_pooling: false
    l2_regularization: 0.001
    
  # Complex CNN - Fixed overfitting with proper regularization
  complex_cnn:
    conv_layers: 4
    filters: [32, 64, 128, 256]
    kernel_size: 3
    activation: "relu"
    dropout: 0.4
    dense_units: 256
    use_batch_norm: true
    use_global_pooling: true
    l2_regularization: 0.001

# Training Configuration
training:
  epochs: 8
  learning_rate: 0.0005  # Reduced learning rate for better convergence
  optimizer: "adam"
  loss_function: "categorical_crossentropy"
  metrics: ["accuracy"]
  early_stopping:
    patience: 5  # Increased patience for complex models
    restore_best_weights: true
  reduce_lr:
    factor: 0.3  # More aggressive learning rate reduction
    patience: 3

# Hyperparameter Tuning
hyperparameter_tuning:
  method: "optuna"  # or "random_search", "optuna"
  param_grid:
    learning_rate: [0.001, 0.0005, 0.0001, 0.00005]
    batch_size: [32, 64, 128]
    dropout: [0.2, 0.3, 0.4, 0.5]
    l2_regularization: [0.0001, 0.001, 0.01]
    optimizer: ["adam", "rmsprop", "sgd"]
  cv_folds: 3
  n_trials: 50  # for random search or optuna
  timeout: 3600  # 1 hour timeout for tuning

# Results and Logging
results:
  models_path: "results/models"
  plots_path: "results/plots"
  logs_path: "results/logs"
  save_best_model: true
  save_training_history: true

# Classes
classes:
  - "rock"
  - "paper"
  - "scissors"
