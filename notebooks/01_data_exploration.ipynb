{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Rock-Paper-Scissors CNN Project\n",
        "## 1. Data Exploration and Analysis\n",
        "\n",
        "This notebook focuses on exploring the Rock-Paper-Scissors dataset, understanding its structure, and performing initial data analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset Information\n",
        "\n",
        "The Rock-Paper-Scissors dataset contains images of hand gestures for the three classes:\n",
        "- **Rock**: Closed fist\n",
        "- **Paper**: Open palm  \n",
        "- **Scissors**: Two fingers extended (index and middle finger)\n",
        "\n",
        "Let's explore the dataset structure and characteristics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define paths\n",
        "data_path = Path('../data/raw')\n",
        "classes = ['rock', 'paper', 'scissors']\n",
        "\n",
        "# Check if data directory exists\n",
        "if not data_path.exists():\n",
        "    print(f\"Data directory {data_path} does not exist.\")\n",
        "    print(\"Please download the dataset from Kaggle and place it in the data/raw directory.\")\n",
        "    print(\"Dataset URL: https://www.kaggle.com/datasets/drgfreeman/rockpaperscissors\")\n",
        "else:\n",
        "    print(f\"Data directory found: {data_path}\")\n",
        "    \n",
        "    # Explore directory structure\n",
        "    for class_name in classes:\n",
        "        class_path = data_path / class_name\n",
        "        if class_path.exists():\n",
        "            num_images = len(list(class_path.glob('*.png')))\n",
        "            print(f\"{class_name}: {num_images} images\")\n",
        "        else:\n",
        "            print(f\"{class_name}: directory not found\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset Statistics\n",
        "\n",
        "Let's analyze the distribution of images across classes and examine some sample images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Collect dataset statistics\n",
        "dataset_stats = {}\n",
        "total_images = 0\n",
        "\n",
        "for class_name in classes:\n",
        "    class_path = data_path / class_name\n",
        "    if class_path.exists():\n",
        "        images = list(class_path.glob('*.png'))\n",
        "        num_images = len(images)\n",
        "        dataset_stats[class_name] = num_images\n",
        "        total_images += num_images\n",
        "        \n",
        "        # Get image dimensions from first image\n",
        "        if images:\n",
        "            sample_img = Image.open(images[0])\n",
        "            print(f\"{class_name}: {num_images} images, sample size: {sample_img.size}\")\n",
        "\n",
        "print(f\"\\nTotal images: {total_images}\")\n",
        "\n",
        "# Create visualization of class distribution\n",
        "if dataset_stats:\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    \n",
        "    # Bar plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    bars = plt.bar(dataset_stats.keys(), dataset_stats.values(), \n",
        "                   color=['#ff9999', '#66b3ff', '#99ff99'])\n",
        "    plt.title('Distribution of Images by Class', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel('Number of Images')\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2., height + 10,\n",
        "                f'{int(height)}', ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    # Pie chart\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.pie(dataset_stats.values(), labels=dataset_stats.keys(), autopct='%1.1f%%', \n",
        "            colors=['#ff9999', '#66b3ff', '#99ff99'], startangle=90)\n",
        "    plt.title('Class Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Print detailed statistics\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"DATASET STATISTICS SUMMARY\")\n",
        "    print(\"=\"*50)\n",
        "    for class_name, count in dataset_stats.items():\n",
        "        percentage = (count / total_images) * 100\n",
        "        print(f\"{class_name.upper()}: {count:,} images ({percentage:.1f}%)\")\n",
        "    print(f\"\\nTOTAL: {total_images:,} images\")\n",
        "    print(\"=\"*50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sample Images Visualization\n",
        "\n",
        "Let's examine sample images from each class to understand the visual characteristics and variations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display sample images from each class\n",
        "fig, axes = plt.subplots(3, 5, figsize=(15, 9))\n",
        "fig.suptitle('Sample Images from Each Class', fontsize=16, fontweight='bold')\n",
        "\n",
        "for i, class_name in enumerate(classes):\n",
        "    class_path = data_path / class_name\n",
        "    if class_path.exists():\n",
        "        images = list(class_path.glob('*.png'))\n",
        "        \n",
        "        for j in range(5):\n",
        "            if j < len(images):\n",
        "                img = Image.open(images[j])\n",
        "                axes[i, j].imshow(img)\n",
        "                axes[i, j].set_title(f'{class_name.capitalize()} {j+1}', fontweight='bold')\n",
        "                axes[i, j].axis('off')\n",
        "            else:\n",
        "                axes[i, j].text(0.5, 0.5, 'No data', ha='center', va='center', \n",
        "                               transform=axes[i, j].transAxes, fontsize=12)\n",
        "                axes[i, j].axis('off')\n",
        "    else:\n",
        "        for j in range(5):\n",
        "            axes[i, j].text(0.5, 0.5, 'No data', ha='center', va='center',\n",
        "                           transform=axes[i, j].transAxes, fontsize=12)\n",
        "            axes[i, j].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Image Analysis\n",
        "\n",
        "Let's analyze the technical characteristics of the images (dimensions, color channels, etc.).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze image characteristics\n",
        "image_analysis = {}\n",
        "\n",
        "for class_name in classes:\n",
        "    class_path = data_path / class_name\n",
        "    if class_path.exists():\n",
        "        images = list(class_path.glob('*.png'))\n",
        "        \n",
        "        if images:\n",
        "            # Sample a few images for analysis\n",
        "            sample_size = min(20, len(images))\n",
        "            sample_images = np.random.choice(images, sample_size, replace=False)\n",
        "            \n",
        "            dimensions = []\n",
        "            channels = []\n",
        "            file_sizes = []\n",
        "            \n",
        "            for img_path in sample_images:\n",
        "                img = Image.open(img_path)\n",
        "                dimensions.append(img.size)  # (width, height)\n",
        "                channels.append(len(img.getbands()))\n",
        "                file_sizes.append(img_path.stat().st_size / 1024)  # KB\n",
        "            \n",
        "            image_analysis[class_name] = {\n",
        "                'dimensions': dimensions,\n",
        "                'channels': channels,\n",
        "                'file_sizes': file_sizes,\n",
        "                'sample_size': sample_size\n",
        "            }\n",
        "\n",
        "# Display analysis results\n",
        "print(\"IMAGE CHARACTERISTICS ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for class_name, analysis in image_analysis.items():\n",
        "    print(f\"\\n{class_name.upper()}:\")\n",
        "    print(f\"  Sample size: {analysis['sample_size']}\")\n",
        "    print(f\"  Unique dimensions: {set(analysis['dimensions'])}\")\n",
        "    print(f\"  Color channels: {set(analysis['channels'])}\")\n",
        "    \n",
        "    # Calculate statistics\n",
        "    avg_width = np.mean([dim[0] for dim in analysis['dimensions']])\n",
        "    avg_height = np.mean([dim[1] for dim in analysis['dimensions']])\n",
        "    avg_file_size = np.mean(analysis['file_sizes'])\n",
        "    \n",
        "    print(f\"  Average dimensions: {avg_width:.0f} x {avg_height:.0f}\")\n",
        "    print(f\"  Average file size: {avg_file_size:.1f} KB\")\n",
        "    print(f\"  File size range: {min(analysis['file_sizes']):.1f} - {max(analysis['file_sizes']):.1f} KB\")\n",
        "\n",
        "# Create visualization of image dimensions\n",
        "if image_analysis:\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "    \n",
        "    for i, (class_name, analysis) in enumerate(image_analysis.items()):\n",
        "        widths = [dim[0] for dim in analysis['dimensions']]\n",
        "        heights = [dim[1] for dim in analysis['dimensions']]\n",
        "        \n",
        "        axes[i].scatter(widths, heights, alpha=0.7, s=50)\n",
        "        axes[i].set_title(f'{class_name.capitalize()} - Image Dimensions')\n",
        "        axes[i].set_xlabel('Width (pixels)')\n",
        "        axes[i].set_ylabel('Height (pixels)')\n",
        "        axes[i].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Add average point\n",
        "        avg_w, avg_h = np.mean(widths), np.mean(heights)\n",
        "        axes[i].scatter(avg_w, avg_h, color='red', s=100, marker='x', linewidth=3)\n",
        "        axes[i].text(avg_w, avg_h, f'Avg: {avg_w:.0f}x{avg_h:.0f}', \n",
        "                    ha='center', va='bottom', fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Quality Assessment\n",
        "\n",
        "Let's check for any potential issues with the dataset including corrupted images and class balance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for corrupted images\n",
        "corrupted_images = []\n",
        "total_checked = 0\n",
        "\n",
        "print(\"CHECKING FOR CORRUPTED IMAGES...\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "for class_name in classes:\n",
        "    class_path = data_path / class_name\n",
        "    if class_path.exists():\n",
        "        images = list(class_path.glob('*.png'))\n",
        "        \n",
        "        for img_path in images:\n",
        "            total_checked += 1\n",
        "            try:\n",
        "                img = Image.open(img_path)\n",
        "                img.verify()  # Verify the image\n",
        "            except Exception as e:\n",
        "                corrupted_images.append((str(img_path), str(e)))\n",
        "\n",
        "print(f\"Total images checked: {total_checked}\")\n",
        "print(f\"Corrupted images: {len(corrupted_images)}\")\n",
        "\n",
        "if corrupted_images:\n",
        "    print(\"\\nCorrupted images found:\")\n",
        "    for img_path, error in corrupted_images:\n",
        "        print(f\"  {img_path}: {error}\")\n",
        "else:\n",
        "    print(\"\\n✅ No corrupted images found!\")\n",
        "\n",
        "# Check class balance\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"CLASS BALANCE ANALYSIS\")\n",
        "print(\"=\"*40)\n",
        "\n",
        "if dataset_stats:\n",
        "    min_count = min(dataset_stats.values())\n",
        "    max_count = max(dataset_stats.values())\n",
        "    balance_ratio = max_count / min_count\n",
        "    \n",
        "    print(f\"Minimum class count: {min_count}\")\n",
        "    print(f\"Maximum class count: {max_count}\")\n",
        "    print(f\"Balance ratio: {balance_ratio:.2f}\")\n",
        "    \n",
        "    if balance_ratio <= 1.1:\n",
        "        print(\"✅ Dataset is well balanced\")\n",
        "    elif balance_ratio <= 1.5:\n",
        "        print(\"⚠️ Dataset has minor imbalance\")\n",
        "    else:\n",
        "        print(\"❌ Dataset has significant imbalance\")\n",
        "        \n",
        "    # Calculate imbalance percentages\n",
        "    for class_name, count in dataset_stats.items():\n",
        "        imbalance = ((count - min_count) / min_count) * 100\n",
        "        print(f\"{class_name}: {imbalance:+.1f}% from minimum\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"DATA QUALITY SUMMARY\")\n",
        "print(\"=\"*40)\n",
        "print(f\"✅ Total images: {total_images:,}\")\n",
        "print(f\"✅ Corrupted images: {len(corrupted_images)}\")\n",
        "print(f\"✅ Classes: {len(classes)}\")\n",
        "print(f\"✅ Image format: PNG\")\n",
        "print(f\"✅ Color channels: RGB (3 channels)\")\n",
        "print(\"=\"*40)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary and Next Steps\n",
        "\n",
        "Based on the data exploration, we can summarize our findings and plan the next steps for the project.\n",
        "\n",
        "**Key Findings:**\n",
        "1. **Dataset Structure**: The dataset contains images organized in three folders (rock, paper, scissors)\n",
        "2. **Class Distribution**: [To be filled after running the analysis]\n",
        "3. **Image Characteristics**: [To be filled after running the analysis]\n",
        "4. **Data Quality**: [To be filled after running the analysis]\n",
        "\n",
        "**Next Steps:**\n",
        "- Data preprocessing and normalization\n",
        "- Train/validation/test split (70/20/10)\n",
        "- Data augmentation strategies\n",
        "- Model architecture design and implementation\n",
        "- Hyperparameter tuning\n",
        "- Model evaluation and analysis\n",
        "\n",
        "**Project Requirements Addressed:**\n",
        "✅ **Data Exploration**: Thorough exploration of the dataset with visualizations\n",
        "✅ **Dataset Summary**: Comprehensive analysis of dataset characteristics\n",
        "✅ **Data Quality Assessment**: Checking for corrupted images and class balance\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
